{
  "hash": "7858d5a62670f979326430e59b89b074",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 06\"\nauthor: \"Bill Perry\"\nexecute:\n  freeze: auto\n  cache: true\n  echo: true\n  keep-md: true # retains the images when you start again\n  message: false\n  warning: false\n  fig-height: 4\n  fig-width: 4\n  paged-print: false\nformat:\n  html:\n    toc: false\n    output-file: \"06_01_lecture_powerpoint_html.html\"\n    embed-resources: true\n    self-contained: true\n    max-width: 80ch  # Limits line length to approximately 80 characters\n    css: ../../css/lecture.css\n  revealjs:\n    output-file: \"06_01_lecture_powerpoint_slides.html\"\n    self-contained: true\n    css: ../../css/lecture.css\n    slide-number: true\n    transition: fade\n  docx:\n    default: true\n    toc: false\n    toc-depth: 3\n    number-sections: false\n    highlight-style: github\n    reference-doc: ../../ms_templates/custom-reference.docx\n    css: msword.css\n    embed-resources: true\n  pptx:\n    reference-doc: ../../ms_templates/lecture_template.pptx \n    embed-resources: true\neditor: visual\n---\n\n\n\n\n\n\n\n\n\n\n# Lecture 5: Review\n\n::::: columns\n::: {.column width=\"60%\"}\nCovered\n\n-   Statistical inference fundamentals\n-   Hypothesis testing principles\n-   T Distributions\n-   One sample T Tests\n-   Two sample T\n:::\n\n::: {.column width=\"40%\"}\n![](images/clipboard-536528302.png){width=\"214\"}\n:::\n:::::\n\n# **Lecture 6:** Overview\n\n::::: columns\n::: {.column width=\"60%\"}\n## The objectives:\n\n-   p-values\n-   Brief review\n-   H test for a single population\n-   1- and 2-sided tests\n-   Hypothesis tests for two populations\n-   Assumptions of parametric tests\n:::\n\n::: {.column width=\"40%\"}\n![](images/pine_needles.jpg){width=\"225\"}\n:::\n:::::\n\n# **Lecture 6:** Statistical hypothesis testing\n\n::::: columns\n::: {.column width=\"60%\"}\n-   Major goal of statistics:\n    -   inferences about populations from samples...\n        -   assign degree of confidence to inferences\n    -   Statistical hypothesis testing:\n        -   formalized approach to inference\n    -   Hypotheses ask whether samples come from populations with certain properties\n    -   Often interested in questions about population means\n        -   but other questions are of interest\n:::\n\n::: {.column width=\"40%\"}\n![](images/pine_tree.png){width=\"250\"}\n:::\n:::::\n\n# **Lecture 6:** Statistical hypothesis testing\n\n::::: columns\n::: {.column width=\"60%\"}\nUseful hypotheses:\n\n-   Rely on specifying\n\n    -   Ho is the hypothesis of “no effect”\n\n        -   two samples from population with same mean\n        -   sample is from population of mean = X\n\n    -   Ha (research or alternate hypothesis)\n\n        -   is the opposite of the Ho\n        -   or predicts that there is an effect of x on y\n        -   *but does NOT suggest a direction which is a prediciton*\n:::\n\n::: {.column width=\"40%\"}\n\\-![](images/two_branches.jpg){width=\"250\"}\n:::\n:::::\n\n# **Lecture 6:** Statistical hypothesis testing\n\n::::: columns\n::: {.column width=\"60%\"}\nTogether Ho and Ha encompass all possible outcomes:\n\n-   Ho: µ=0, Ha: µ ≠ 0\n\n    -   mean equals 0 or mean does not equal 0\n\n-   Ho: µ = 35, Ha: µ ≠ 35\n\n    -   mean equals 35 or mean does not equal 35\n\n-   Ho: µ1 = µ2, Ha: µ1 ≠ µ2\n\n    -   mean of population 1 equals mean of population 2 or it does not\n\n-   Ho: µ \\> 0, Ha: µ ≤ 0\n\n    -   can be directional mean is greater than 0 or mean is not equal or less than 0\n\n    -   this becomes a one sided test as it predicts only one direction\n:::\n\n::: {.column width=\"40%\"}\n![](images/two_branches.jpg){width=\"250\"}\n:::\n:::::\n\n# **Lecture 6:** Statistical hypothesis testing\n\n::::: columns\n::: {.column width=\"60%\"}\nStatistical tests assess likelihood of the null hypothesis being true\n\n-   If the Ho is likely false, then Ha assumed to be correct\n-   More precisely:\n    -   the long run probability of obtaining sample value (or more extreme one) if the null hypothesis is true\n        -   p(data\\|Ho) - the probability of observing the data given that the null hypothesis Ho is true\n:::\n\n::: {.column width=\"40%\"}\n![](images/two_branches.jpg){width=\"250\"}\n:::\n:::::\n\n# **Lecture 6:** Statistical hypothesis testing\n\n::::: columns\n::: {.column width=\"60%\"}\nHypothesis tests\n\n-   Expressed as p-value (0-never to 1-always )\n-   Interpret p-value as:\n    -   probability of obtaining sample value of statistic (or more extreme one) if Ho is true\n-   High p-value:\n    -   high probability of obtaining sample statistic under Ho\n        -   if the null hypothesis (Ho) were true, you would frequently observe data similar to your sample statistic\n        -   your observed results are quite compatible with what the null hypothesis predicts\n-   Low p-value: low probability of obtaining sample statistic under Ho\n    -   if the null hypothesis (Ho) were true, you would rarely observe data similar to or more extreme than your sample statistic\n    -   Your results are unusual under the null hypothesis, suggesting that either you've witnessed a rare event or the null hypothesis may be incorrect\n:::\n\n::: {.column width=\"40%\"}\n![](images/two_branches.jpg){width=\"250\"}\n:::\n:::::\n\n# **Lecture 6:** Statistical hypothesis testing\n\nStatistical test results:\n\n-   p = 0.3 means that if I repeated the study 100 times, I would get this (or more extreme) result due to chance 30 times\n\n-   p = 0.03 means that if I repeated the study 100 times, I would get this (or more extreme) result due to chance 3 times\n\n*Which p-value suggests Ho likely false?*\n\nAt what point reject Ho?\n\np \\< 0.05 conventional “significance threshold” (α = alpha or p value)\n\np \\< 0.05 means: if Ho is true and we repeated the study 100 times\n\n-   we would get this (or more extreme) result less than 5 times due to chance\n\n# **Lecture 6:** Statistical hypothesis testing\n\nStatistical test results:\n\n-   α is the rate at which we will reject a true null hypothesis (Type I error rate)\n-   Lowering α will lower likelihood of incorrectly rejecting a true null hypothesis (e.g., 0.01, 0.001)\n-   *Both Hs and α are specified* *BEFORE collection of data and analysis*\n\nTraditionally α=0.05 is used as a cut off for rejecting null hypothesis\n\nThere is nothing magical about 0.05 - actual p-values need to be reported - also need to decide prior to study\n\n| p-value range | Interpretation |\n|----|----|\n| P \\> 0.10 | No evidence against Ho - data appear consistent with Ho |\n| 0.05 \\< P \\< 0.10 | Weak evidence against the Ho in favor of Ha |\n| 0.01 \\< P \\< 0.05 | Moderate evidence against Ho in favor of Ha |\n| 0.001 \\< P \\< 0.01 | Strong evidence against Ho in favor of Ha |\n| P \\< 0.001 | Very strong evidence against Ho in favor of Ha |\n\n# **Lecture 6:** Understanding P-values\n\n::::: columns\n::: {.column width=\"60%\"}\nA **p-value** is the probability of observing the sample result (or something more extreme) if the null hypothesis is true.\n\n-   **Common interpretations:**\n    -   p \\< 0.05: Strong evidence against H₀\n    -   0.05 ≤ p \\< 0.10: Moderate evidence against H₀\n    -   p ≥ 0.10: Insufficient evidence against H₀\n-   **Common misinterpretations:**\n    -   p-value is NOT the probability that H₀ is true\n\n    -   p-value is NOT the probability that results occurred by chance\n\n    -   Statistical significance ≠ practical significance\n-   Note that there is a difference in how to state the hypotheses\n    -   one sample TTEST\n\n    -   two sample TTEST\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-1-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Lecture 6:** Statistical hypothesis testing\n\n![](images/clipboard-3329723408.png){width=\"493\"}\n\n# **Lecture 6:** Statistical hypothesis testing\n\n:::: columns\n::: {.column width=\"60%\"}\nFisher:\n\np-value as informal measure of discrepancy between data and Ho\n\n“If p is between 0.1 and 0.9 there is certainly no reason to suspect the hypothesis tested. If it is below 0.02 it is strongly indicated that the hypothesis fails to account for the whole of the facts. We shall not often be astray if we draw a conventional line at .05 …”\n:::\n\n![](images/clipboard-694363384.png){width=\"221\"}\n::::\n\n# **Decision errors**\n\n::::: columns\n::: {.column width=\"60%\"}\n-   Even good studies can reach incorrect conclusions\n-   \"Decision errors\"\n-   Two types of decision errors\n-   Want to know probability of making these errors\n:::\n\n::: {.column width=\"40%\"}\n![](images/clipboard-1430957016.png){width=\"370\"}\n:::\n:::::\n\n# **Type I and Type II Errors**\n\n::::: columns\n::: {.column width=\"60%\"}\n-   **Type I error rate**\n    -   **α**: wrongly reject H₀ when it's true\n    -   α = 0.05 means a type I error rate of 5%\n-   **Type II error rate, β**\n    -   wrongly fail to reject H₀ when it's false\n-   **Power = 1-β**: probability of correctly rejecting H₀ when H₁ is true\n-   Inverse relationship between type I and type II error - but not straightforward\n-   Result of chance - sample not representative of population\n-   Which type of error is more dangerous?\n:::\n\n::: {.column width=\"40%\"}\n![](images/clipboard-4092094638.png){width=\"422\"}\n\nthe dotted line is the alpha = 0.05\n:::\n:::::\n\n# **Lecture 6:** Type I and Type II Errors\n\n::::: columns\n::: {.column width=\"60%\"}\nWhen making decisions based on hypothesis tests, two types of errors can occur:\n\n**Type I Error (False Positive)** - Rejecting H₀ when it's actually true - Probability = α (significance level) - \"Finding an effect that isn't real\"\n\n**Type II Error (False Negative)** - Failing to reject H₀ when it's actually false - Probability = β - \"Missing an effect that is real\"\n\n**Statistical Power = 1 - β** - Probability of correctly rejecting a false H₀ - Increases with: - Larger sample size - Larger effect size - Lower variability - Higher α level\n\nThe red area represents the power in the experiment\n\nThe farther part the means the lower the beta error is... or you have higher power.\n:::\n\n::: {.column width=\"40%\"}\n![](images/clipboard-3204206464.png){width=\"373\"}\n:::\n:::::\n\n# **Lecture 6:** Type I and Type II Errors\n\n::::: columns\n::: {.column width=\"60%\"}\nWhen making decisions based on hypothesis tests, two types of errors can occur:\n\n**Type I Error (False Positive)** - Rejecting H₀ when it's actually true - Probability = α (significance level) - \"Finding an effect that isn't real\"\n\n**Type II Error (False Negative)** - Failing to reject H₀ when it's actually false - Probability = β - \"Missing an effect that is real\"\n\n**Statistical Power = 1 - β** - Probability of correctly rejecting a false H₀ - Increases with: - Larger sample size - Larger effect size - Lower variability - Higher α level\n\nThe red area represents the power in the experiment\n\nThe farther part the means the lower the beta error is... or you have higher power.\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-2-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n::: callout-tip\n## Practice Exercise 6: Interpreting P-values and Errors\n\nGiven the following scenarios, identify whether a Type I or Type II error might have occurred:\n\n1.  A researcher concludes that a new fishing regulation increased grayling size, when in fact it had no effect.\n2.  A study fails to detect a real decline in grayling population due to warming water, concluding there was no effect.\n3.  Let's calculate the power of our t-test to detect a 30 mm difference in length between lakes:\n\n-   pooled standard deviation\n\n    -   This is the combined standard deviation of both groups weighted by respective degrees of freedom.\n\n-   Cohen's d\n\n    -   standardized difference between means - here assuming a difference of 30 units (mm)\n    -   `delta = 0.6741298`: The standardized effect size (Cohen's d)\n\n-   \n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\nlibrary(patchwork)\nlibrary(tidyverse)\n\ngrayling_df <- read_csv(\"data/gray_I3_I8.csv\")\ni3_df <- grayling_df %>% filter(lake==\"I3\")\ni8_df <- grayling_df %>% filter(lake==\"I8\")\n# Calculate power for detecting a 30 mm difference\n\n\n\nn1 <- nrow(i3_df)\nn2 <- nrow(i8_df)\nsd_pooled <- sqrt((var(i3_df$length_mm) * (n1-1) + \n                  var(i8_df$length_mm) * (n2-1)) / \n                  (n1 + n2 - 2))\n\n# Calculate power\neffect_size <- 30 / sd_pooled  # Cohen's d\ndf <- n1 + n2 - 2\nalpha <- 0.05\npower <- power.t.test(n = min(n1, n2), \n                     delta = effect_size,\n                     sd = 1,  # Using standardized effect size\n                     sig.level = alpha,\n                     type = \"two.sample\",\n                     alternative = \"two.sided\")\n\n# Display results\npower\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Two-sample t test power calculation \n\n              n = 66\n          delta = 0.6741298\n             sd = 1\n      sig.level = 0.05\n          power = 0.9702076\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n\n# What is Power\n\nStatistical power represents the probability of detecting a true effect (rejecting the null hypothesis when it is false). In this case, with a power of 97%, there's a 97% chance of detecting a true difference of 30 units between the means of the two groups if such a difference actually exists.\n\nA power analysis like this is typically done for one of these purposes:\n\n1.  Before data collection to determine required sample size\n2.  After a study to evaluate if the sample size was adequate\n3.  To determine the minimum detectable effect size with the given sample\n\nWith 97% power, this test has excellent ability to detect the specified effect size. Generally, **80% power is considered acceptable**, so 97% indicates a very well-powered study for detecting a difference of 30mm between the groups.\n\n# **Lecture 5:** Error Bars and Their Interpretation\n\n::::: columns\n::: {.column width=\"60%\"}\nError bars are graphical representations of the variability of data that show:\n\n-   The **precision** of a measurement\n-   The **uncertainty** around an estimate\n-   A **confidence interval** for a parameter\n\nCommon types of error bars:\n\n1.  **Standard Error (SE)**: Shows precision of the mean\n2.  **Standard Deviation (SD)**: Shows variability in the data\n3.  **Confidence Interval (CI)**: Shows plausible range for parameter\n\nWhen interpreting graphs:\n\n-   Always check what the error bars represent\n-   Non-overlapping 95% CI bars suggest statistically significant differences\n-   Error bars help assess both statistical and practical significance\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-4-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Lecture 5:** Sampling and Pseudoreplication\n\n::::: columns\n::: {.column width=\"60%\"}\n**Pseudoreplication** occurs when measurements that are not independent are analyzed as if they were independent.\n\n-   A critical consideration in experimental design\n-   Results in underestimated standard errors and confidence intervals\n-   Leads to inflated Type I error rates (false positives)\n\n**Examples of pseudoreplication:**\n\n-   Measuring the same individual multiple times\n-   Treating multiple fish from the same tank as independent\n-   Using multiple data points from a single site\n\n**How to avoid pseudoreplication:**\n\n-   Identify the true experimental unit\n-   Use appropriate statistical techniques (e.g., mixed models)\n-   Be clear about the level of replication\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-5-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Lecture 5:** Practical Applications in Fish Biology\n\n::::: columns\n::: {.column width=\"60%\"}\nThe statistical concepts we've covered today are essential for fisheries biologists and ecologists:\n\n-   **Standard error** quantifies uncertainty in growth rate estimates\n-   **Confidence intervals** provide plausible ranges for population parameters\n-   **Hypothesis testing** evaluates effects of management practices\n-   **P-values** determine significance of environmental impacts\n\n**Real-world applications:**\n\n-   Assessing population health and structure\n-   Evaluating effectiveness of fishing regulations\n-   Quantifying relationships between fish size and habitat variables\n-   Predicting impacts of climate change on fish populations\n-   Designing effective conservation strategies\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-6-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}