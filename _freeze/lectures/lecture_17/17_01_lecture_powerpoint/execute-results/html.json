{
  "hash": "c71c91ed9ed516daebb71e36bddbaa00",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 17 - Multivariate STATS \"\nauthor: \"Bill Perry\"\nexecute:\n  freeze: auto\n  cache: true\n  echo: true\n  keep-md: true\n  message: false\n  warning: false\n  fig-height: 5\n  fig-width: 4\n  paged-print: false\nformat:\n  html:\n    toc: false\n    output-file: \"17_01_lecture_powerpoint_html.html\"\n    embed-resources: true\n    self-contained: true\n    max-width: 80ch\n    css: ../../css/lecture.css\n  revealjs:\n    output-file: \"17_01_lecture_powerpoint_slides.html\"\n    self-contained: true\n    css: ../../css/lecture.css\n    slide-number: true\n    transition: fade\n  docx:\n    default: true\n    toc: false\n    toc-depth: 3\n    number-sections: true\n    highlight-style: github\n    reference-doc: ../../ms_templates/custom-reference.docx\n    css: msword.css\n    embed-resources: true\n  pptx:\n    reference-doc: ../../ms_templates/lecture_template.pptx \n    embed-resources: true\neditor: visual\n---\n\n\n\n\n\n\n\n\n# \n\n# Introduction to Multivariate Statistics\n\n::::: columns\n::: {.column width=\"60%\"}\n## Overview\n\n-   Multivariate data: multiple variables per object\n-   Types of multivariate analyses\n    -   Functional vs. structural methods\n    -   R-mode vs. Q-mode analyses\n-   Eigenvectors, eigenvalues, and components\n-   Distance and dissimilarity measures\n-   Data transformations and standardization\n-   Screening multivariate data\n-   MANOVA\n:::\n\n::: {.column width=\"40%\"}\n:::\n:::::\n\n# Multivariate Data\n\n::::: columns\n::: {.column width=\"60%\"}\n-   Multiple variables recorded about each object (individual, quadrat, site, etc.)\n-   Objects: rows (i = 1 to n)\n-   Variables: columns (j = 1 to p)\n-   Examples:\n    -   Stream sites with multiple chemical parameters\n    -   Species with multiple morphological traits\n    -   Sample units with multiple species abundances\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_01_lecture_powerpoint_files/figure-html/unnamed-chunk-1-1.png){width=384}\n:::\n:::\n\n\n\n\n\n:::\n:::::\n\n::: callout-tip\n# Multivariate data vs. multivariate analysis\n\nWe've already seen multivariate data in multiple regression and multi-factor ANOVA, but now we'll look at cases with multiple response variables.\n:::\n\n# Multivariate Statistics in Ecology\n\n::::: columns\n::: {.column width=\"60%\"}\n## Functional vs. Structural Methods\n\n**Functional methods**: - Clear response and predictor variables - Goal: relate Y's to X's - Examples: MANOVA, PERMANOVA\n\n**Structural methods**: - Find patterns/structure in data - Often no clear predictors - Examples: PCA, NMDS, Cluster Analysis\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_01_lecture_powerpoint_files/figure-html/unnamed-chunk-2-1.png){width=384}\n:::\n:::\n\n\n\n\n\n:::\n:::::\n\n# Structural Methods in Multivariate Analysis\n\n::::: columns\n::: {.column width=\"60%\"}\n## Two Main Approaches\n\n**Scaling/Ordination Methods**: - Reduce dimensions with new derived variables - Summarize patterns in data - Examples: PCA, CCA\n\n**Dissimilarity-Based Methods**: - Measure dissimilarity between objects - Visualize relationships between objects - Examples: NMDS, Cluster Analysis\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_01_lecture_powerpoint_files/figure-html/unnamed-chunk-3-1.png){width=384}\n:::\n:::\n\n\n\n\n\n:::\n:::::\n\n# Eigenvectors, Eigenvalues, and Components\n\n::::: columns\n::: {.column width=\"60%\"}\n-   Goal: derive new variables (principal components) that explain variation in data\n-   Components are linear combinations of original variables:\n    -   z<sub>ik</sub> = c<sub>1</sub>y<sub>i1</sub> + c<sub>2</sub>y<sub>i2</sub> + ... + c<sub>p</sub>y<sub>ip</sub>\n-   Properties of derived variables:\n    -   First component explains most variation\n    -   Second explains most remaining variation\n    -   Components are uncorrelated with each other\n    -   As many components as original variables\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_01_lecture_powerpoint_files/figure-html/unnamed-chunk-4-1.png){width=384}\n:::\n:::\n\n\n\n\n\n:::\n:::::\n\n::: callout-tip\n# Key concept\n\nEigenvalues (λ) represent the amount of variation explained by each new derived variable, while eigenvectors contain the coefficients showing how original variables contribute to each component.\n:::\n\n# Distance and Dissimilarity Measures\n\n::::: columns\n::: {.column width=\"60%\"}\n-   Measure how different objects are in multivariate space\n-   Common measures:\n    -   **Euclidean distance**: direct geometric distance\n    -   **Manhattan distance**: sum of absolute differences\n    -   **Bray-Curtis**: good for species abundance data\n    -   **Kulczynski**: for abundance data with zeros\n-   Used in cluster analysis, MDS, and other techniques\n-   Create dissimilarity matrices for analysis\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_01_lecture_powerpoint_files/figure-html/unnamed-chunk-5-1.png){width=384}\n:::\n:::\n\n\n\n\n\n:::\n:::::\n\n# Data Transformations & Standardization\n\n::::: columns\n::: {.column width=\"60%\"}\n## Common Approaches\n\n**Transformations**: - Log transformation for skewed data - Root transformations for count data - Fourth-root for species abundance data\n\n**Standardization**: - Centering: subtract mean (mean = 0) - Standardization: divide by SD (SD = 1) - Crucial for variables with different units - May not be appropriate for species data\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_01_lecture_powerpoint_files/figure-html/unnamed-chunk-6-1.png){width=384}\n:::\n:::\n\n\n\n\n\n:::\n:::::\n\n::: callout-tip\n# Why standardize?\n\nStandardization ensures all variables contribute equally to the analysis regardless of their original units or scales of measurement. Without it, variables with larger values or variances would dominate the results.\n:::\n\n# Multivariate Graphics\n\n::::: columns\n::: {.column width=\"60%\"}\n## Visual Representation Methods\n\n-   **SPLOMS/Scatterplot Matrices**: show bivariate relationships\n-   **Star plots**: display multiple variables per object\n-   **Chernoff faces**: represent variables as facial features\n-   **Heatmaps**: visualize data matrices with color\n-   **Biplots**: show objects and variables together\n-   **Ordination plots**: visualize relationships in reduced dimensions\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_01_lecture_powerpoint_files/figure-html/unnamed-chunk-7-1.png){width=384}\n:::\n:::\n\n\n\n\n\n:::\n:::::\n\n# Screening Multivariate Data\n\n::::: columns\n::: {.column width=\"60%\"}\n## Key Issues to Check\n\n**Multivariate Outliers**: - Objects with unusual patterns across variables - Detected with Mahalanobis distance (d²) - Test against χ² distribution with p df\n\n**Missing Observations**: - Common approaches: - Deletion: remove affected object or variable - Imputation: estimate missing values - Maximum likelihood methods - Multiple imputation\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_01_lecture_powerpoint_files/figure-html/unnamed-chunk-8-1.png){width=384}\n:::\n:::\n\n\n\n\n\n:::\n:::::\n\n# MANOVA (Multivariate Analysis of Variance)\n\n::::: columns\n::: {.column width=\"60%\"}\n-   Multivariate extension of ANOVA\n-   Tests for differences in group centroids based on multiple response variables\n-   Advantages over multiple ANOVAs:\n    -   Controls family-wise error rate\n    -   Accounts for correlations between variables\n    -   More powerful when variables are correlated\n-   Common test statistics:\n    -   Wilk's lambda (λ)\n    -   Pillai's trace\n    -   Hotelling-Lawley trace\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_01_lecture_powerpoint_files/figure-html/unnamed-chunk-9-1.png){width=384}\n:::\n:::\n\n\n\n\n\n:::\n:::::\n\n::: callout-tip\n# MANOVA Assumptions\n\n-   Multivariate normality\n-   Homogeneity of variance-covariance matrices\n-   No extreme multivariate outliers\n-   Independence of observations\n:::\n\n# Discriminant Function Analysis\n\n::::: columns\n::: {.column width=\"60%\"}\n-   Mathematically similar to MANOVA\n-   Used for:\n    -   Testing differences between groups (like MANOVA)\n    -   Identifying variables that separate groups\n    -   Classifying observations into groups\n-   Creates linear combinations (discriminant functions) that maximize between-group differences\n-   Can assess how well classification performs\n-   Jackknifed classification provides more realistic success rates\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_01_lecture_powerpoint_files/figure-html/unnamed-chunk-10-1.png){width=384}\n:::\n:::\n\n\n\n\n\n:::\n:::::\n\n# Summary\n\n::::: columns\n::: {.column width=\"60%\"}\n## Key Concepts\n\n1.  **Multivariate data** requires special techniques to account for correlations between variables\n\n2.  **Functional methods** (MANOVA) test hypotheses about group differences\n\n3.  **Structural methods** (PCA, NMDS) find patterns in data\n\n4.  **Distance measures** quantify similarities between objects\n\n5.  **Data standardization** is crucial for variables with different units\n\n6.  **Multivariate graphics** help visualize complex relationships\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17_01_lecture_powerpoint_files/figure-html/unnamed-chunk-11-1.png){width=384}\n:::\n:::\n\n\n\n\n\n:::\n:::::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}