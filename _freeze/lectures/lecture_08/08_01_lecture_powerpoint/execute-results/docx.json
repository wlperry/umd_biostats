{
  "hash": "d45e6dd7a3f24a1b0220e9d7683268bc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 8\"\nauthor: \"Bill Perry\"\nexecute:\n  freeze: auto\n  cache: true\n  echo: true\n  keep-md: true # retains the images when you start again\n  message: false\n  warning: false\n  fig-height: 3\n  fig-width: 3\n  paged-print: false\nformat:\n  html:\n    toc: false\n    output-file: \"08_lecture_powerpoint_html.html\"\n    embed-resources: true\n    self-contained: true\n    max-width: 80ch  # Limits line length to approximately 80 characters\n    css: ../../css/lecture.css\n  revealjs:\n    output-file: \"08_lecture_powerpoint_slides.html\"\n    self-contained: true\n    css: ../../css/lecture.css\n    slide-number: true\n    transition: fade\n  docx:\n    default: true\n    toc: false\n    toc-depth: 3\n    number-sections: false\n    highlight-style: github\n    reference-doc: ../../ms_templates/custom-reference.docx\n    css: msword.css\n    embed-resources: true\n  pptx:\n    reference-doc: ../../ms_templates/lecture_template.pptx \n    embed-resources: true\neditor: visual\n---\n\n\n\n\n\n\n\n\n\n\n\n\n# Lecture 7: Review\n\n::::::: columns\n::: {.column width=\"60%\"}\nCovered\n\n-   Assumption tests for parametric tests\n-   Statistical vs Biological significance\n-   Nonparametric tests\n    -   Welch's t-test: *when distribution normal but variance unequal*\n    -   Permutation test for two samples: *when distribution not normal (but both groups should still have similar distributions and \\~equal variance)*\n    -   Mann-Whitney-Wilcoxon test: *when distribution not normal and/or outliers are present (but both groups should still have similar distributions and \\~equal variance)*\n:::\n\n::: {.column width=\"40%\"}\n![](images/mouse.jpg)\n:::\n\n# **Lecture 8:** Overview\n\n::: {.column width=\"60%\"}\n## The objectives:\n\n-   Decision errors\n-   Data exploration and transformation\n-   Exploratory graphical data analysis\n-   Graphical testing of assumptions\n-   Data transformation and standardization\n-   Outliers\n-   \n:::\n\n::: {.column width=\"40%\"}\n![](images/clipboard-3204206464.png){width=\"525\"}\n:::\n:::::::\n\n# **Decision errors**\n\n::::: columns\n::: {.column width=\"60%\"}\n-   Even good studies can reach incorrect conclusions\n-   \"Decision errors\"\n-   Two types of decision errors\n-   Want to know probability of making these errors\n:::\n\n::: {.column width=\"40%\"}\n\\<![](images/clipboard-1430957016.png)\n:::\n:::::\n\n# **Type I and Type II Errors**\n\n::::: columns\n::: {.column width=\"60%\"}\n-   **Type I error rate**\n    -   **α**: wrongly reject H₀ when it's true\n    -   α = 0.05 means a type I error rate of 5%\n-   **Type II error rate, β**\n    -   wrongly fail to reject H₀ when it's false\n-   **Power = 1-β**: probability of correctly rejecting H₀ when H₁ is true\n-   Inverse relationship between type I and type II error - but not straightforward\n-   Result of chance - sample not representative of population\n-   Which type of error is more dangerous?\n:::\n\n::: {.column width=\"40%\"}\n\\<![](images/clipboard-4092094638.png)\n\nthe dotted line is also the alpha = 0.05\n:::\n:::::\n\n# **Exploratory graphical data analysis**\n\n::::: columns\n::: {.column width=\"60%\"}\n-   Graphical exploration is one of first steps in data analysis:\n    -   Detect data entry errors\n    -   Pattern exploration\n    -   Assess assumptions of tests\n    -   Detect outliers\n-   Most important Q: shape of distribution?\n-   Determined by density plots: \"density of different values\"\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Let's examine our pine needle data\n# pine_data %>% \n#   group_by(wind) %>%\n#   summarize(\n#     n = n(),\n#     mean = mean(length_mm),\n#     sd = sd(length_mm),\n#     min = min(length_mm),\n#     max = max(length_mm)\n#   )\n```\n:::\n\n\n\n\n\n\n\n\n\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Histogram with density\nggplot(pine_data, aes(x = length_mm)) +\n  geom_histogram(aes(y = ..density..), \n                 fill = \"lightblue\", \n                 color = \"black\",\n                 bins = 10) +\n  geom_density(alpha = 0.5, fill = \"steelblue\") +\n  labs(title = \"Pine Needle Length Distribution\",\n       x = \"Length (mm)\", \n       y = \"Density\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](08_01_lecture_powerpoint_files/figure-docx/unnamed-chunk-1-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Types of Exploratory Plots**\n\n::::: columns\n::: {.column width=\"60%\"}\n-   **Histograms**: data broken into intervals, number of observations in each interval plotted on y-axis\n    -   Not great for small samples\n    -   \n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Histogram with density\nggplot(pine_data, aes(x = length_mm)) +\n  geom_histogram(bins = 10) +\n  labs(title = \"Pine Needle Length Distribution\",\n       x = \"Length (mm)\", \n       y = \"Density\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](08_01_lecture_powerpoint_files/figure-docx/unnamed-chunk-2-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Types of Exploratory Plots**\n\n::::: columns\n::: {.column width=\"60%\"}\n-   **Kernel density plot**: data broken into intervals, normal distribution assumed within each interval, sum of density functions plotted\n:::\n\n::: {.column width=\"0%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Kernel density plot\nggplot(pine_data, aes(x = length_mm)) +\n  geom_density(fill = \"skyblue\", alpha = 0.5) +\n  labs(title = \"Pine Needle Length Distribution\",\n       x = \"Length (mm)\", \n       y = \"Density\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](08_01_lecture_powerpoint_files/figure-docx/unnamed-chunk-3-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Types of Exploratory Plots**\n\n::::: columns\n::: {.column width=\"60%\"}\n-   **Dotplots**: each value represented as a dot along the measurement scale\n:::\n\n::: {.column width=\"0%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Dot plot of pine needle lengths\nggplot(pine_data, aes(x = 0, y = length_mm)) +\n  geom_point(size = 2, alpha = 0.5,\n             position = position_dodge2(width=.15)) +\n  # geom_jitter(width = 0.1, height = .05, size = 2, alpha = 0.5) +\n  labs(title = \"Pine Needle Length Distribution\",\n       x = \"Length (mm)\", \n       y = \"\") +\n  scale_x_continuous(limits = c(-.5, .5))+\n  theme_minimal() \n```\n\n::: {.cell-output-display}\n![](08_01_lecture_powerpoint_files/figure-docx/unnamed-chunk-4-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Types of Exploratory Plots**\n\n::::: columns\n::: {.column width=\"60%\"}\n-   **Boxplot**: displays median, quartiles, range, outliers\n    -   Good when n \\> \\~10\n\n![](images/clipboard-3945509904.png){width=\"369\"}\n:::\n\n::: {.column width=\"0%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Kernel density plot\n#| message: false\n#| warning: false\n#| fig-height: 4\n#| fig-width: 3\n#| include: true\n#| paged-print: false\n#| \nggplot(pine_data, aes(x = length_mm)) +\n  geom_boxplot()+\n  labs(title = \"Pine Needle Length Distribution\",\n       x = \"Length (mm)\", \n       y = \"Density\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](08_01_lecture_powerpoint_files/figure-docx/unnamed-chunk-5-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Types of Exploratory Plots**\n\n::::: columns\n::: {.column width=\"60%\"}\n-   **Scatter plot**: display of bivariate data\n    -   Shows distribution, outliers, non-linearity\n-   **Scatter matrix**: like scatterplot, but for multiple variables -will show later\n:::\n\n::: {.column width=\"0%\"}\n\\\n\\<![](images/clipboard-3590207847.png){width=\"296\"}\n:::\n:::::\n\n# **Types of Exploratory Plots**\n\n::::: columns\n::: {.column width=\"60%\"}\n-   **QQ plots**: compare quantiles of distribution against theoretical distribution (e.g. normal)\n:::\n\n::: {.column width=\"0%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# qqplot\n# QQ plot for pine needle lengths\nggplot(pine_data, aes(sample = length_mm)) +\n  stat_qq() +\n  stat_qq_line() +\n  labs(title = \"QQ Plot of Pine Needle Lengths\",\n       x = \"Theoretical Quantiles\", \n       y = \"Sample Quantiles\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](08_01_lecture_powerpoint_files/figure-docx/unnamed-chunk-6-1.png)\n:::\n\n```{.r .cell-code}\n# ggplot(pine_data, aes(sample = length_mm)) +\n#   stat_qq(color = \"darkgreen\", size = 2, alpha = 0.6) +\n#   stat_qq_line(color = \"blue\", linewidth = 1, linetype = \"dashed\") +\n#   labs(title = \"QQ Plot of Pine Needle Lengths\",\n#        x = \"Theoretical Quantiles\", \n#        y = \"Sample Quantiles\") +\n#   theme_minimal()\n```\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Data transformation and standardization**\n\n::::: columns\n::: {.column width=\"60%\"}\n-   If data don't meet distributional assumptions can try transforming:\n    -   Approximate a normal distribution of data and errors\n    -   Improve homogeneity of variance\n    -   Reduce effect of outliers\n    -   Improve linearity for regression analysis\n    -   Reduce interactions between variables\n-   Data transformation changes the scale on which data are measured\n-   Common transformations:\n    -   Right-skewed data: power (root) transformations, log10 transformation\n    -   Left-skewed data: power transformations, log10 of (constant - x)\n    -   Percentages/proportions (bounded): Arcsine transformation\n    -   Rank transformation: most extreme, leads to loss of information\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Let's apply a log transformation to our pine needle data\nlt_df <- read_csv(\"data/lake_trout.csv\")\n\n# Let's apply a log transformation to our pine needle data\nlt_df <- lt_df %>%\n  mutate(log_mass = log10(mass_g +1))\n\n# Create before and after plots to show transformation effect\nlt_hist_1_plot <- ggplot(lt_df, aes(x = mass_g)) +\n  geom_histogram(bins = 10, fill = \"lightblue\", color = \"black\") +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Original Data\", x = \"Length (mm)\", y = \"Count\") +\n  theme_minimal()\n\nlt_qq_1_plot <- ggplot(lt_df, aes(sample = mass_g)) +\n  geom_qq() + \n  geom_qq_line() +\n  labs(title = \"QQ Plot - Original\", x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n  theme_minimal()\n\nlt_hist_2_log_plot <- ggplot(lt_df, aes(x = log_mass)) +\n  geom_histogram(bins = 10, fill = \"lightgreen\", color = \"black\") +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Log-Transformed Data\", x = \"log10(Length)\", y = \"Count\") +\n  theme_minimal()\n\nlt_qq_2_log_plot <-  ggplot(lt_df, aes(sample = log_mass)) +\n  geom_qq() + \n  geom_qq_line() +\n  labs(title = \"QQ Plot - Log-Transformed\", x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n  theme_minimal()\n\n# Combine plots\n(lt_hist_1_plot + lt_qq_1_plot) / (lt_hist_2_log_plot + lt_qq_2_log_plot)+\n  plot_annotation(\n    title = \"Lake Trout Mass and Log(Mass+1)\"\n  )\n```\n\n::: {.cell-output-display}\n![](08_01_lecture_powerpoint_files/figure-docx/unnamed-chunk-7-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Data transformation and standardization**\n\n::::: columns\n::: {.column width=\"60%\"}\n-   Common transformations:\n    -   Right-skewed data: power (root) transformations, log10 transformation\n    -   Left-skewed data: power transformations, log10 of (constant - x)\n    -   Percentages/proportions (bounded): Arcsine transformation\n    -   Rank transformation: most extreme, leads to loss of information\n:::\n\n::: {.column width=\"40%\"}\n\\<![](images/clipboard-2123280961.png){width=\"288\"}\n:::\n:::::\n\n# \n\n# **Outliers**\n\n::::: columns\n::: {.column width=\"60%\"}\n-   Outliers: unusual values that are outside the range of most other observations\n    -   Can significantly affect results of analysis\n-   Outliers identified using:\n    -   Formal tests (Dixon's Q, Cook's D)\n    -   Graphically, using boxplots or QQ plots\n-   What to do with outliers? Depends why they happened:\n    -   If obvious data entry error, can be removed\n    -   If part of the data:\n        -   Rerun analysis with and without outliers, report both results\n        -   Use tests robust to outliers or transform data\n    -   Unethical to remove inconvenient outliers\n    -   \n:::\n\n::: {.column width=\"40%\"}\n\\<![](images/clipboard-1519725416.png)\n:::\n:::::\n\n# **Final Activity:** Take home messages\n\n::::: columns\n::: {.column width=\"60%\"}\n**Common assumptions for tests:**\n\n1.  Normality: Data comes from normally distributed populations\n2.  Equal variances (for two-sample tests)\n3.  Independence: Observations are independent\n4.  No outliers: Extreme values can influence results\n\nWhat can we do if our data violates these assumptions?\n:::\n\n::: {.column width=\"40%\"}\nAlternatives\n\n-   Data transformation (log, square root, etc.)\n-   Non-parametric tests\n-   Bootstrapping approaches\n:::\n:::::\n\n# **Summary and Conclusions**\n\nIn this activity, we've:\n\n1.  Explored decision errors (Type I and Type II) and their implications\n2.  Learned various methods for exploratory data analysis\n3.  Discussed data transformations to meet statistical assumptions\n4.  Examined approaches for handling outliers\n\n**Key takeaways:**\n\n-   Always explore your data visually before formal analysis\n-   Consider the assumptions of statistical tests and check if they are met\n-   Choose appropriate transformations or alternative tests when assumptions are violated\n-   Be transparent about handling outliers and report all analytical decisions\n\n# **What do you see as the key points?**\n\nThings that stood out\n\n1.  \n\n2.  \n\n3.  \n\n# **What are the muddy points?**\n\nWhat does not make sense or what questions do you have...\n\nWhat makes you nervous?\n\n1.  \n\n2.  \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}