{
  "hash": "8def4b1a64869df0bfae1908cc485f1e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lecture 04: Probability and Inference\"\nauthor: \"Bill Perry\"\nexecute:\n  freeze: auto\n  cache: true\n  echo: true\n  keep-md: true # retains the images when you start again\n  message: false\n  warning: false\n  fig-height: 3\n  fig-width: 3\n  paged-print: false\nformat:\n  html:\n    toc: false\n    output-file: \"04_01_lecture_powerpoint_html.html\"\n    embed-resources: true\n    self-contained: true\n    max-width: 80ch  # Limits line length to approximately 80 characters\n    css: ../../css/lecture.css\n  revealjs:\n    output-file: \"04_01_lecture_powerpoint_slides.html\"\n    self-contained: true\n    css: ../../css/lecture.css\n    slide-number: true\n    transition: fade\n  docx:\n    default: true\n    toc: false\n    toc-depth: 3\n    number-sections: false\n    highlight-style: github\n    reference-doc: ../../ms_templates/custom-reference.docx\n    css: msword.css\n    embed-resources: true\n  pptx:\n    reference-doc: ../../ms_templates/lecture_template.pptx \n    embed-resources: true\neditor: visual\n---\n\n\n\n\n\n\n\n\n\n\n\n\n# **Lecture 4: Probability and Statistical Inference**\n\n::::: columns\n::: {.column width=\"60%\"}\n-   Review of probability distributions\n-   Standard normal distribution and Z-scores\n-   Standard error and confidence intervals\n-   Statistical inference fundamentals\n-   Hypothesis testing principles\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-2-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n::: callout-tip\n## Practice Exercise 1: Exploring the Grayling Dataset\n\nLet's explore the Arctic grayling data from lakes I3 and I8. Use the `grayling_df` data frame to create basic summary statistics.\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Write your code here to explore the basic structure of the data\n# also note plottig a box plot is really useful\nstr(grayling_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nspc_tbl_ [168 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ site           : num [1:168] 113 113 113 113 113 113 113 113 113 113 ...\n $ lake           : chr [1:168] \"I3\" \"I3\" \"I3\" \"I3\" ...\n $ species        : chr [1:168] \"arctic grayling\" \"arctic grayling\" \"arctic grayling\" \"arctic grayling\" ...\n $ total_length_mm: num [1:168] 266 290 262 275 240 265 265 253 246 203 ...\n $ mass_g         : num [1:168] 135 185 145 160 105 145 150 130 130 71 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   site = col_double(),\n  ..   lake = col_character(),\n  ..   species = col_character(),\n  ..   total_length_mm = col_double(),\n  ..   mass_g = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(grayling_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      site         lake             species          total_length_mm\n Min.   :113   Length:168         Length:168         Min.   :191.0  \n 1st Qu.:113   Class :character   Class :character   1st Qu.:270.8  \n Median :118   Mode  :character   Mode  :character   Median :324.5  \n Mean   :116                                         Mean   :324.5  \n 3rd Qu.:118                                         3rd Qu.:377.0  \n Max.   :118                                         Max.   :440.0  \n                                                                    \n     mass_g     \n Min.   : 53.0  \n 1st Qu.:151.2  \n Median :340.0  \n Mean   :351.2  \n 3rd Qu.:519.5  \n Max.   :889.0  \n NA's   :2      \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n\n# **Lecture 4:** Probability Distributions\n\n::::: columns\n::: {.column width=\"60%\"}\n## Probability Distribution Functions\n\n-   A **probability distribution** describes the probability of different outcomes in an experiment\n-   We've seen histograms of observed data\n-   Theoretical distributions help us model and understand real-world data\n-   We will focus on a standard normal distribution and a t distribution\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-4-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Lecture 4:** The Standard Normal Distribution\n\n::::: columns\n::: {.column width=\"60%\"}\nThe standard normal distribution is crucial for understanding statistical inference:\n\n-   Has mean (μ) = 0 and standard deviation (σ) = 1\n-   Symmetrical bell-shaped curve\n-   Area under the curve = 1 (total probability)\n-   Approximately:\n    -   68% of data within ±1σ of the mean\n    -   **95% of data within ±2σ of the mean - really 1.96σ**\n    -   99.7% of data within ±3σ of the mean\n\nZ-scores allow us to convert any normal distribution to the standard normal distribution.\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-5-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n::: callout-tip\n## Practice Exercise 2: Calculating Z-scores\n\nLet's practice converting raw values to Z-scores using the Arctic grayling data.\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the mean and standard deviation of fish lengths\nmean_length <- mean(grayling_df$total_length_mm, na.rm = TRUE)\nsd_length <- sd(grayling_df$total_length_mm, na.rm = TRUE)\n\n# Calculate Z-scores for fish lengths\ngrayling_df <- grayling_df %>%\n  mutate(z_score = (total_length_mm - mean_length) / sd_length)\n\n# View the first few rows with Z-scores\nhead(grayling_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 6\n   site lake  species         total_length_mm mass_g z_score\n  <dbl> <chr> <chr>                     <dbl>  <dbl>   <dbl>\n1   113 I3    arctic grayling             266    135  -0.900\n2   113 I3    arctic grayling             290    185  -0.531\n3   113 I3    arctic grayling             262    145  -0.961\n4   113 I3    arctic grayling             275    160  -0.761\n5   113 I3    arctic grayling             240    105  -1.30 \n6   113 I3    arctic grayling             265    145  -0.915\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# What proportion of fish are within 1 standard deviation of the mean?\nwithin_1sd <- sum(abs(grayling_df$z_score) <= 1, na.rm = TRUE) / sum(!is.na(grayling_df$z_score))\ncat(\"Proportion within 1 SD:\", round(within_1sd * 100, 1), \"%\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nProportion within 1 SD: 64.3 %\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n# Lecuture 4: Standard normal distribution\n\n::::: columns\n::: {.column width=\"60%\"}\nYou want to know things about this population like\n\n-   probability of afish having a certain length (e.g., \\> 300 mm)\n-   Can solve this by integrating under curve\n-   But it is tedious to do every time\n-   Instead\n    -   we can use the *standard normal distribution* (SND)\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  mean_length\n        <dbl>\n1        266.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-8-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# \n\n# Lecture 4: Standard normal distribution\n\n::::: columns\n::: {.column width=\"60%\"}\nStandard Normal Distribution\n\n-   \"benchmark\" normal distribution with µ = 0, σ = 1\n-   The Standard Normal Distribution is defined so that:\n    -   \\~68% of the curve area within +/- 1 σ of the mean,\n\n    -   \\~95% within +/- 2 σ of the mean,\n\n    -   \\~99.7% within +/- 3 σ of the mean\n\n\\*remember σ = standard deviation\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-9-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# Lecture 4: Standard normal distribution\n\n::::: columns\n::: {.column width=\"60%\"}\nAreas under curve of Standard Normal Distribution\n\n-   Have been calculated for a range of sample sizes\n-   Can be looked up in z-table\n-   No need to integrate\n-   Any normally distributed data can be standardized\n    -   transformed into the standard normal distribution\n    -   a value can ber looked up in a table\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-10-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# \n\n# Lecture 4: Standard normal distribution\n\n::::: columns\n::: {.column width=\"60%\"}\nDone by converting original data points to z-scores\n\n-   Z-scores calculated as:\n\n## $\\text{Z = }\\frac{X_i-\\mu}{\\sigma}$\n\n-   z = z-score for observation\n-   xi = original observation\n-   µ = mean of data distribution\n-   σ = SD of data distribution\n\nSo lets do this for a fish that is 300mm long and guess the probability of catching something larger\n\nz = (300 - 265.61)/28.3 = 1.215194\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ni3_stats <- gray_i3_df %>%\n  summarize(\n    mean_length = round(mean(total_length_mm, na.rm = TRUE), 2),\n    sd_length = sd(total_length_mm, na.rm = TRUE),\n    n = sum(!is.na(total_length_mm)),\n    se_length = round(sd_length / sqrt(sum(!is.na(total_length_mm))), 2),\n    .groups = \"drop\"\n  )\n\n# Display the results\ni3_stats\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  mean_length sd_length     n se_length\n        <dbl>     <dbl> <int>     <dbl>\n1        266.      28.3    66      3.48\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# Lecture 4: Standard normal distribution\n\n::::: columns\n::: {.column width=\"60%\"}\nDone by converting original data points to z-scores\n\n-   Z-scores calculated as:\n\n## $\\text{Z = }\\frac{X_i-\\mu}{\\sigma}$\n\n-   z = z-score for observation\n-   xi = original observation\n-   µ = mean of data distribution\n-   σ = SD of data distribution\n\nSo lets do this for a fish that is 320mm long and guess the probability of catching something larger\n\nz = (320 - 265.61)/28.3 = 1.92\n\nor .9726 in table or 97.3% is the area left of the curve and\n\n100 - 97.3 = 2.7% or 2.7% of fish are expected to be longer\n:::\n\n::: {.column width=\"40%\"}\n![](images/clipboard-1995791111.png)\n:::\n:::::\n\n# \n\n# **Lecture 4:** Sampling a population - Std Error\n\n::::: columns\n::: {.column width=\"60%\"}\nThe **standard error of the mean (SEM)** tells us how precise our sample mean is as an estimate of the population mean.\n\nStandard Error Formula: $$ SE_{\\bar{Y}} = \\frac{s}{\\sqrt{n}} $$\n\nWhere:\n\n-   $s$ is the sample standard deviation\n-   $n$ is the sample size\n\n**Key properties:**\n\n-   SEM decreases as sample size increases\n-   SEM is used to construct confidence intervals\n-   SEM measures the precision of the sample mean\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-12-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n::: callout-tip\n## Practice Exercise 5: Sampling Distributions\n\nLet's explore how sample size affects our estimates by taking samples of different sizes:\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set seed for reproducibility\nset.seed(456)\n\n# Create samples of different sizes\nsmall_sample <- grayling_df %>% sample_n(5)\nmedium_sample <- grayling_df %>% sample_n(30)\nlarge_sample <- grayling_df %>% sample_n(125)\n\n# Calculate mean and standard error for each sample\nsmall_mean <- mean(small_sample$total_length_mm, na.rm = TRUE)\nsmall_se <- sd(small_sample$total_length_mm, na.rm = TRUE) / sqrt(10)\n\nmedium_mean <- mean(medium_sample$total_length_mm, na.rm = TRUE)\nmedium_se <- sd(medium_sample$total_length_mm, na.rm = TRUE) / sqrt(30)\n\nlarge_mean <- mean(large_sample$total_length_mm, na.rm = TRUE)\nlarge_se <- sd(large_sample$total_length_mm, na.rm = TRUE) / sqrt(100)\n\n# Create a data frame with the results\nresults <- data.frame(\n  Sample_Size = c(10, 30, 100),\n  Mean = c(small_mean, medium_mean, large_mean),\n  SE = c(small_se, medium_se, large_se)\n)\n\n# Display the results\nresults\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Sample_Size    Mean        SE\n1          10 302.000 26.607330\n2          30 319.200 12.082989\n3         100 323.328  6.478149\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\nWhat do you observe about the standard error as sample size increases? Why does this happen?\n:::\n\n# **Lecture 4:** Estimating µ - population mean\n\n::::: columns\n::: {.column width=\"60%\"}\n## Every sample gives slightly different estimate of µ\n\n-   Can take many samples and calculate means\n-   Plot the frequency distribution of means\n-   Get the \"sampling distribution of means\"\n\n## 3 important properties:\n\n-   Sampling distribution of means (SDM) from normal population will be normal\n-   Large Sampling distribution of means from any population will be normal (Central Limit Theorem)\n-   The mean of Sampling distribution of means will equal µ or the mean\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-14-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Lecture 4:** Estimating µ - population mean\n\n::::: columns\n::: {.column width=\"60%\"}\n## Given above\n\n-   can estimate the standard deviation of sample means\n\n-   \"Standard error of sample mean\"\n\n-   How good is your estimate of population mean? (based on the sample collected)\n\n-   quantifies how much the sample means are expected to vary from samples\n\n-   gives an estimate of the error associated with using $\\bar{y}$ to estimate $\\mu$...\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-15-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Lecture 4:** Estimating µ - population mean\n\n::::: columns\n::: {.column width=\"60%\"}\nNotice: - $s_{\\bar{y}}$ depends on - sample s (standard deviation) - sample n - ($s_{\\bar{y}} = \\frac{s}{\\sqrt{n}}$)\n\nHow and why? - Decreases with sample n - number - increases with sample s - standard deviation\n\n-   Large sample, low s = greater confidence in estimate of $\\mu$\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-16-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# \n\n# **Lecture 4:** Standard Error of the Mean\n\n::::: columns\n::: {.column width=\"60%\"}\nThe **standard error of the mean (SEM)** tells us how precise our sample mean is as an estimate of the population mean.\n\nStandard Error Formula: $$ SE_{\\bar{Y}} = \\frac{s}{\\sqrt{n}} $$\n\nWhere:\n\n-   $s$ is the sample standard deviation\n-   $n$ is the sample size\n\n**Key properties:**\n\n-   SEM decreases as sample size increases\n-   SEM is used to construct confidence intervals\n-   SEM measures the precision of the sample mean\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-17-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Lecture 4:** Confidence Intervals\n\n::::: columns\n::: {.column width=\"60%\"}\nA **confidence interval** is a range of values that is likely to contain the true population parameter.\n\n95% Confidence Interval Formula: $$\\text{95% CI} = \\bar{y} \\pm z \\cdot \\frac{\\sigma}{\\sqrt{n}}$$\n\nWhere:\n\n-   ȳ is the sample mean\n-   𝑛 is the sample size\n-   σ is the population standard deviation\n-   z is the z-value corresponding the probability of the CI\n:::\n\n::: {.column width=\"40%\"}\n![](images/clipboard-2045535544.png)\n:::\n:::::\n\n# **Lecture 4:** Confidence Intervals\n\n::::: columns\n::: {.column width=\"60%\"}\nA **confidence interval** is a range of values that is likely to contain the true population parameter.\n\n**Interpretation:** If we were to take many samples and calculate the 95% CI for each, about 95% of these intervals would contain the true population mean.\n\n**Common misinterpretation:** \"There is a 95% probability that the true mean is in this interval.\"\n\n-   Interpret 95% CI to mean:\n    -   Range of values that contains µ (population mean) with 95% probability\n-   More correctly:\n    -   If we took 100 samples from population\n    -   calculate a CI from each\n    -   95 of the 100 CIs will contain the true population mean - µ\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-18-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# \n\n# **Lecture 4:** Compare the SE and CI plots\n\n::::: columns\n::: {.column width=\"60%\"}\nLets compare what the two plots look like near each other\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-19-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n::: callout-tip\n## Practice Exercise 3: Calculating Standard Error and Confidence Intervals\n\nCalculate the standard error and 95% confidence interval for the mean length of Arctic grayling in each lake.\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the standard error and confidence intervals by lake\nci_results <- grayling_df %>%\n  group_by(lake) %>%\n  summarize(\n    mean_length = round(mean(total_length_mm, na.rm = TRUE), 2),\n    sd_length = sd(total_length_mm, na.rm = TRUE),\n    n = sum(!is.na(total_length_mm)),\n    se_length = round(sd_length / sqrt(n), 2),\n    ci = round(1.96 * se_length, 2),\n    ci_lower = round(mean_length - 1.96 * se_length, 2),\n    ci_upper = round(mean_length + 1.96 * se_length, 2),\n    .groups = \"drop\"\n  )\n\n# Display the results\nci_results\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 8\n  lake  mean_length sd_length     n se_length    ci ci_lower ci_upper\n  <chr>       <dbl>     <dbl> <int>     <dbl> <dbl>    <dbl>    <dbl>\n1 I3           266.      28.3    66      3.48  6.82     259.     272.\n2 I8           363.      52.3   102      5.18 10.2      352.     373.\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\nWhat do these confidence intervals tell us about the difference between lakes?\n:::\n\n# **Lecture 4:** Confidence intervals\n\n:::: columns\n::: {.column width=\"60%\"}\nIn the more typical case DON'T know the population σ\n\n-   estimate it from the samples when don't know the population σ\n-   and when sample size is \\<\\~30)\n-   can't use the standard normal (z) distribution\n\n*Instead, we use Student's t distribution*\n:::\n\n![](images/clipboard-1052237789.png){width=\"375\"}\n::::\n\n# \n\n# **Lecture 4:** Understanding t-distribution\n\n::::: columns\n::: {.column width=\"60%\"}\nWhen sample sizes are small, the **t-distribution** is more appropriate than the normal distribution.\n\n-   Similar to normal distribution but with heavier tails\n-   Shape depends on **degrees of freedom** (df = n-1)\n-   With large df (\\>30), approaches the normal distribution\n-   Used for:\n    -   Small sample sizes\n    -   When population standard deviation is unknown\n    -   Calculating confidence intervals\n    -   Conducting t-tests\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-21-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n::: callout-tip\n## Practice Exercise 4: Using the t-distribution\n\nLet's compare confidence intervals using the normal approximation (z) versus the t-distribution for our fish data.\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate CI using both z and t distributions for a smaller subset\nsmall_sample <- grayling_df %>% \n  filter(lake == \"I3\") %>% \n  slice_sample(n = 10)\n\n# Calculate statistics\nsample_mean <- mean(small_sample$total_length_mm)\nsample_sd <- sd(small_sample$total_length_mm)\nsample_n <- nrow(small_sample)\nsample_se <- sample_sd / sqrt(sample_n)\n\n# Calculate confidence intervals\nz_ci_lower <- sample_mean - 1.96 * sample_se\nz_ci_upper <- sample_mean + 1.96 * sample_se\n\n# For t-distribution, get critical value for 95% CI with df = n-1\nt_crit <- qt(0.975, df = sample_n - 1)\nt_ci_lower <- sample_mean - t_crit * sample_se\nt_ci_upper <- sample_mean + t_crit * sample_se\n\n# Display results\ncat(\"Mean:\", round(sample_mean, 1), \"mm\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean: 255.3 mm\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Standard deviation:\", round(sample_sd, 2), \"mm\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStandard deviation: 26.26 mm\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Standard error:\", round(sample_se, 2), \"mm\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStandard error: 8.31 mm\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"95% CI using z:\", round(z_ci_lower, 1), \"to\", round(z_ci_upper, 1), \"mm\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n95% CI using z: 239 to 271.6 mm\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"95% CI using t:\", round(t_ci_lower, 1), \"to\", round(t_ci_upper, 1), \"mm\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n95% CI using t: 236.5 to 274.1 mm\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"t critical value:\", round(t_crit, 3), \"vs z critical value: 1.96\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nt critical value: 2.262 vs z critical value: 1.96\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n\n# Student's t-distribution\n\n::::: columns\n::: {.column width=\"60%\"}\nTo calculate CI for sample from \"unknown\" population:\n\n## $\\text{CI} = \\bar{y} \\pm t \\cdot \\frac{s}{\\sqrt{n}}$\n\nWhere:\n\n-   ȳ is sample mean\n-   𝑛 is sample size\n-   s is sample standard deviation\n-   t t-value corresponding the probability of the CI\n-   t in t-table for different degrees of freedom (n-1)\n:::\n\n::: {.column width=\"40%\"}\n![](images/clipboard-3203878802.png){width=\"423\"}\n:::\n:::::\n\n# **Lecture 5:** Student's t-distribution\n\n::::: columns\n::: {.column width=\"60%\"}\nHere is a t-table\n\n-   Values of t that correspond to probabilities\n-   Probabilities listed along top\n-   Sample dfs are listed in the left-most column\n-   Probabilities are given for one-tailed and two-tailed \"questions\"\n:::\n\n::: {.column width=\"40%\"}\n![](images/clipboard-3203878802.png){width=\"436\"}\n:::\n:::::\n\n# **Lecture 5:** Student's t-distribution\n\n::::: columns\n::: {.column width=\"60%\"}\nOne-tailed questions: area of distribution left or (right) of a certain value\n\n-   n=20 (df=19) - 90% of the observations found left\n-   t= 1.328 (10% are outside)\n:::\n\n::: {.column width=\"40%\"}\n![](images/clipboard-1822465473.png){width=\"225\"}\n\n![](images/clipboard-641796945.png){width=\"365\"}\n:::\n:::::\n\n# **Lecture 5:** Student's t-distribution\n\n::::: columns\n::: {.column width=\"60%\"}\nTwo-tailed questions refer to area between certain values\n\n-   n= 20 (df=19), 90% of the observations are between\n-   t=-1.729 and t=1.729 (10% are outside)\n:::\n\n::: {.column width=\"40%\"}\n![](images/clipboard-2234740159.png){width=\"271\"}\n\n![](images/clipboard-1734806681.png){width=\"549\"}\n:::\n:::::\n\n# **Lecture 5:** Student's t-distribution\n\n::::: columns\n::: {.column width=\"60%\"}\nLet's calculate CIs again:\n\nUse two-sided test\n\n-   95% CI Sample A: = 272.8 ± 2.262 \\* (37.81/(9\\^0.5)) = 1.650788\n-   The 95% CI is between 244.3 and 301.3\n-   \"The 95% CI for the population mean from sample A is 272.8 ± 28.5\"\n:::\n\n::: {.column width=\"40%\"}\n![](images/clipboard-721472248.png){width=\"563\"}\n:::\n:::::\n\n# \n\n# **Lecture 4:** Intro to Hypothesis Testing\n\n::::: columns\n::: {.column width=\"60%\"}\nHypothesis testing is a systematic way to evaluate research questions using data.\n\n**Key components:**\n\n1.  **Null hypothesis (H₀)**: Typically assumes \"no effect\" or \"no difference\"\n\n2.  **Alternative hypothesis (Hₐ)**: The claim we're trying to support\n\n3.  **Statistical test**: Method for evaluating evidence against H₀\n\n4.  **P-value**: Probability of observing our results (or more extreme) if H₀ is true\n\n5.  **Significance level (α)**: Threshold for rejecting H₀, typically 0.05\n\n**Decision rule**: Reject H₀ if p-value \\< α\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-23-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Lecture 4:** Intro to Hypothesis Testing\n\n::::: columns\n::: {.column width=\"60%\"}\nHypothesis testing is a systematic way to evaluate research questions using data.\n\n**Key components:**\n\n1.  **Null hypothesis (H₀)**: Typically assumes \"no effect\" or \"no difference\"\n\n2.  **Alternative hypothesis (Hₐ)**: The claim we're trying to support\n\n3.  **Statistical test**: Method for evaluating evidence against H₀\n\n4.  **P-value**: Probability of observing our results (or more extreme) if H₀ is true\n\n5.  **Significance level (α)**: Threshold for rejecting H₀, typically 0.05\n\n**Decision rule**: Reject H₀ if p-value \\< α\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-24-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n::: callout-tip\n## Practice Exercise 5: Lets practice a One-Sample t-Test\n\nLet's perform a one-sample t-test to determine if the mean fish length in Toolik Lake differs from 50 mm:\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get only lake I#\ni3_df <- grayling_df %>% filter(lake==\"I3\")\n\n# what is the mean\ni3_mean <- mean(i3_df$total_length_mm, na.rm=TRUE)\ncat(\"Mean:\", round(i3_mean, 1), \"mm\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean: 265.6 mm\n```\n\n\n:::\n\n```{.r .cell-code}\n# Perform a one-sample t-test\nt_test_result <- t.test(i3_df$total_length_mm, mu = 260)\n\n# View the test results\nt_test_result\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  i3_df$total_length_mm\nt = 1.6091, df = 65, p-value = 0.1124\nalternative hypothesis: true mean is not equal to 260\n95 percent confidence interval:\n 258.6481 272.5640\nsample estimates:\nmean of x \n 265.6061 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\nInterpret this test result by answering these questions:\n\n1.  What was the null hypothesis?\n2.  What was the alternative hypothesis?\n3.  What does the p-value tell us?\n4.  Should we reject or fail to reject the null hypothesis at α = 0.05?\n5.  What is the practical interpretation of this result for fish biologists?\n:::\n\n::: callout-tip\n## Practice Exercise 6: Formulating Hypotheses\n\nFor the following research questions about Arctic grayling, write the null and alternative hypotheses:\n\n1.  Are fish in Lake I8 longer than fish in Lake I3?\n2.  Is the mean length of Arctic grayling in these lakes different from 300 mm?\n3.  Is there a relationship between fish length and mass?\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Let's test one of these hypotheses: Are fish in Lake I8 longer than fish in Lake I3?\n\n# Perform an independent t-test\nt_test_result <- t.test(total_length_mm ~ lake, data = grayling_df, \n                       alternative = \"less\")  # H₀: μ_I3 ≥ μ_I8, H₁: μ_I3 < μ_I8\n\n# Display the results\nt_test_result\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  total_length_mm by lake\nt = -15.532, df = 161.63, p-value < 2.2e-16\nalternative hypothesis: true difference in means between group I3 and group I8 is less than 0\n95 percent confidence interval:\n      -Inf -86.66138\nsample estimates:\nmean in group I3 mean in group I8 \n        265.6061         362.5980 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\nBased on this t-test, what can we conclude about the difference in fish length between the two lakes?\n:::\n\n# **Lecture 4:** Understanding P-values\n\n::::: columns\n::: {.column width=\"60%\"}\nA **p-value** is the probability of observing the sample result (or something more extreme) if the null hypothesis is true.\n\n**Common interpretations:** - p \\< 0.05: Strong evidence against H₀ - 0.05 ≤ p \\< 0.10: Moderate evidence against H₀ - p ≥ 0.10: Insufficient evidence against H₀\n\n**Common misinterpretations:** - p-value is NOT the probability that H₀ is true - p-value is NOT the probability that results occurred by chance - Statistical significance ≠ practical significance\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-27-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Lecture 4:** Type I and Type II Errors\n\n::::: columns\n::: {.column width=\"60%\"}\nWhen making decisions based on hypothesis tests, two types of errors can occur:\n\n**Type I Error (False Positive)** - Rejecting H₀ when it's actually true - Probability = α (significance level) - \"Finding an effect that isn't real\"\n\n**Type II Error (False Negative)** - Failing to reject H₀ when it's actually false - Probability = β - \"Missing an effect that is real\"\n\n**Statistical Power = 1 - β** - Probability of correctly rejecting a false H₀ - Increases with: - Larger sample size - Larger effect size - Lower variability - Higher α level\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-28-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n::: callout-tip\n## Practice Exercise 6: Interpreting P-values and Errors\n\nGiven the following scenarios, identify whether a Type I or Type II error might have occurred:\n\n1.  A researcher concludes that a new fishing regulation increased grayling size, when in fact it had no effect.\n\n2.  A study fails to detect a real decline in grayling population due to warming water, concluding there was no effect.\n\n3.  Let's calculate the power of our t-test to detect a 30 mm difference in length between lakes:\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate power for detecting a 30 mm difference\n# First determine parameters\nlake_I3 <- grayling_df %>% filter(lake == \"I3\")\nlake_I8 <- grayling_df %>% filter(lake == \"I8\") \n\nn1 <- nrow(lake_I3)\nn2 <- nrow(lake_I8)\nsd_pooled <- sqrt((var(lake_I3$total_length_mm) * (n1-1) + \n                  var(lake_I8$total_length_mm) * (n2-1)) / \n                  (n1 + n2 - 2))\n\n# Calculate power\neffect_size <- 30 / sd_pooled  # Cohen's d\ndf <- n1 + n2 - 2\nalpha <- 0.05\npower <- power.t.test(n = min(n1, n2), \n                     delta = effect_size,\n                     sd = 1,  # Using standardized effect size\n                     sig.level = alpha,\n                     type = \"two.sample\",\n                     alternative = \"two.sided\")\n\n# Display results\npower\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Two-sample t test power calculation \n\n              n = 66\n          delta = 0.6741298\n             sd = 1\n      sig.level = 0.05\n          power = 0.9702076\n    alternative = two.sided\n\nNOTE: n is number in *each* group\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n\n# **Lecture 4:** Summary\n\n::::: columns\n::: {.column width=\"60%\"}\n**Key concepts covered:**\n\n1.  **Probability distributions** model random phenomena\n    -   Normal distribution is especially important\n    -   Z-scores standardize measurements\n2.  **Standard error** measures precision of estimates\n    -   Decreases with larger sample sizes\n    -   Used to construct confidence intervals\n3.  **Confidence intervals** express uncertainty\n    -   Provide plausible range for parameters\n    -   95% CI: `mean ± 1.96 × SE`\n4.  **Hypothesis testing** evaluates claims\n    -   Null vs. alternative hypotheses\n    -   P-values quantify evidence against H₀\n    -   Consider both statistical and practical significance\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-30-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n::: callout-tip\n## Final Exercise: Comprehensive Analysis\n\nNow that we've covered the key concepts, let's perform a complete analysis of the Arctic grayling data:\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Comprehensive analysis of Arctic grayling data\n# 1. Data visualization\nlength_boxplot <- grayling_df %>%\n  ggplot(aes(x = lake, y = total_length_mm, fill = lake)) +\n  geom_boxplot() +\n  labs(title = \"Fish Length by Lake\",\n       x = \"Lake\",\n       y = \"Length (mm)\") +\n  theme_minimal()\n\n# 2. Compare means with t-test\nlength_ttest <- t.test(total_length_mm ~ lake, data = grayling_df)\n\n# 3. Length-mass relationship\nlength_mass_model <- lm(mass_g ~ total_length_mm * lake, data = grayling_df)\nmodel_summary <- summary(length_mass_model)\n\n# 4. Display results\nlength_boxplot\n```\n\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-31-1.png)\n:::\n\n```{.r .cell-code}\nlength_ttest\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  total_length_mm by lake\nt = -15.532, df = 161.63, p-value < 2.2e-16\nalternative hypothesis: true difference in means between group I3 and group I8 is not equal to 0\n95 percent confidence interval:\n -109.32342  -84.66053\nsample estimates:\nmean in group I3 mean in group I8 \n        265.6061         362.5980 \n```\n\n\n:::\n\n```{.r .cell-code}\nmodel_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mass_g ~ total_length_mm * lake, data = grayling_df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-151.223  -14.839   -0.764   10.670  153.130 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            -219.3313    47.9087  -4.578 9.30e-06 ***\ntotal_length_mm           1.3924     0.1794   7.763 8.88e-13 ***\nlakeI8                 -522.5506    56.5882  -9.234  < 2e-16 ***\ntotal_length_mm:lakeI8    1.9738     0.1972  10.009  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 40.93 on 162 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.9644,\tAdjusted R-squared:  0.9637 \nF-statistic:  1461 on 3 and 162 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n\n```{.r .cell-code}\n# 5. Calculate 95% confidence intervals for each lake\nci_results <- grayling_df %>%\n  group_by(lake) %>%\n  summarize(\n    mean_length = mean(total_length_mm, na.rm = TRUE),\n    sd_length = sd(total_length_mm, na.rm = TRUE),\n    n = sum(!is.na(total_length_mm)),\n    se_length = sd_length / sqrt(n),\n    t_crit = qt(0.975, df = n - 1),\n    margin_error = t_crit * se_length,\n    ci_lower = mean_length - margin_error,\n    ci_upper = mean_length + margin_error,\n    .groups = \"drop\"\n  )\n\n# Display confidence intervals\nci_results\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 9\n  lake  mean_length sd_length     n se_length t_crit margin_error ci_lower\n  <chr>       <dbl>     <dbl> <int>     <dbl>  <dbl>        <dbl>    <dbl>\n1 I3           266.      28.3    66      3.48   2.00         6.96     259.\n2 I8           363.      52.3   102      5.18   1.98        10.3      352.\n# ℹ 1 more variable: ci_upper <dbl>\n```\n\n\n:::\n\n```{.r .cell-code}\n# 6. Visualize regression with confidence intervals\nregression_plot <- grayling_df %>%\n  ggplot(aes(x = total_length_mm, y = mass_g, color = lake)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE) +\n  labs(title = \"Length-Mass Relationship by Lake\",\n       x = \"Length (mm)\",\n       y = \"Mass (g)\") +\n  theme_minimal()\n\nregression_plot\n```\n\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-31-2.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n\nBased on this analysis: 1. Are there significant differences in fish length between the two lakes? 2. How does the length-mass relationship differ between lakes? 3. What conclusions can you draw about Arctic grayling in these two lakes?\n:::\n\n# **Lecture 4:** Error Bars and Their Interpretation\n\n::::: columns\n::: {.column width=\"60%\"}\nError bars are graphical representations of the variability of data that show:\n\n-   The **precision** of a measurement\n-   The **uncertainty** around an estimate\n-   A **confidence interval** for a parameter\n\nCommon types of error bars: 1. **Standard Error (SE)**: Shows precision of the mean 2. **Standard Deviation (SD)**: Shows variability in the data 3. **Confidence Interval (CI)**: Shows plausible range for parameter\n\nWhen interpreting graphs: - Always check what the error bars represent - Non-overlapping 95% CI bars suggest statistically significant differences - Error bars help assess both statistical and practical significance\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-32-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Lecture 4:** Sampling and Pseudoreplication\n\n::::: columns\n::: {.column width=\"60%\"}\n**Pseudoreplication** occurs when measurements that are not independent are analyzed as if they were independent.\n\n-   A critical consideration in experimental design\n-   Results in underestimated standard errors and confidence intervals\n-   Leads to inflated Type I error rates (false positives)\n\n**Examples of pseudoreplication:** - Measuring the same individual multiple times - Treating multiple fish from the same tank as independent - Using multiple data points from a single site\n\n**How to avoid pseudoreplication:** - Identify the true experimental unit - Use appropriate statistical techniques (e.g., mixed models) - Be clear about the level of replication\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-33-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Lecture 4:** Practical Applications in Fish Biology\n\n::::: columns\n::: {.column width=\"60%\"}\nThe statistical concepts we've covered today are essential for fisheries biologists and ecologists:\n\n-   **Z-scores** help identify unusual fish sizes in a population\n-   **Standard error** quantifies uncertainty in growth rate estimates\n-   **Confidence intervals** provide plausible ranges for population parameters\n-   **Hypothesis testing** evaluates effects of management practices\n-   **P-values** determine significance of environmental impacts\n\n**Real-world applications:** - Assessing population health and structure - Evaluating effectiveness of fishing regulations - Quantifying relationships between fish size and habitat variables - Predicting impacts of climate change on fish populations - Designing effective conservation strategies\n:::\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_01_lecture_powerpoint_files/figure-pptx/unnamed-chunk-34-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\n\n:::\n:::::\n\n# **Lecture 4:** Next Steps in Statistical Analysis\n\nIn future lectures, we'll explore:\n\n-   One-sample and two-sample t-tests\n-   Analysis of variance (ANOVA)\n-   Linear regression and correlation\n-   Chi-square tests\n-   Non-parametric methods\n-   Multiple regression and model selection\n-   Mixed effects models\n\nEach method builds on the statistical foundation we've established today, applying probability concepts to make inferences from data.\n\n::: callout-tip\n## Learning Resources\n\n-   Practice problems in the textbook (Chapter 4 & 5)\n-   Online resources:\n    -   Khan Academy: Probability and Statistics\n    -   StatQuest with Josh Starmer (YouTube channel)\n    -   R for Data Science (r4ds.had.co.nz)\n-   Office hours: Wednesdays 2-4pm\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}